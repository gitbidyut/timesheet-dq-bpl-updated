version: 0.2

env:
  variables:
    AWS_REGION: eu-west-1
    IMAGE_TAG: latest
    CHECKSUM_S3: s3://bpl-timesheet-artifacts-dev/dq_checksum.txt
    IMAGE_REPO_NAME: timesheet-dq-processing
    SNS_TOPIC_ARN: arn:aws:sns:eu-west-1:361509912577:timesheet-dq-results
    SAGEMAKER_ROLE_ARN: "arn:aws:iam::361509912577:role/sagemaker-pipeline-smoketest-role"
phases:
  pre_build:
    commands:
      - echo "Checking if data_quality.py changed"
      - |
        # Compute current checksum
        set -e 
        CURRENT_SUM=$(sha256sum data_quality.py | awk '{print $1}')
        echo "Current checksum: $CURRENT_SUM"
      
        if aws s3 ls $CHECKSUM_S3 >/dev/null 2>&1; then
          PREV_SUM=$(aws s3 cp $CHECKSUM_S3 -)
        else
          PREV_SUM=""
        fi
      
        # Compare
        if [ "$CURRENT_SUM" != "$PREV_SUM" ]; then
          echo "data_quality.py changed - Docker build required"
          export BUILD_DOCKER=true 
        else
          echo "data_quality.py unchanged  - skipping Docker build"
          export BUILD_DOCKER=false 
        fi  
      
  build:
    commands:
      - |
        set -e
        if [ "$BUILD_DOCKER" = "true" ]; then
          echo "Building Docker image"
          docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_URI=$ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com
          aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ECR_URI

          docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $ECR_URI/$IMAGE_REPO_NAME:$IMAGE_TAG
          docker push $ECR_URI/$IMAGE_REPO_NAME:$IMAGE_TAG
          echo $CURRENT_SUM | aws s3 cp - $CHECKSUM_S3

        else
          echo "Docker build skipped"
        fi  
       

  post_build:
    commands:
      # OPTIONAL: trigger SageMaker Pipeline
      - echo "Starting SageMaker Pipeline execution"
      - | 
        set -e
        TIMESTAMP=$(date -u +"%Y%m%d-%H%M%S")
        JOB_NAME="timesheet-dq-${TIMESTAMP}"

        echo "Creating Processing Job: $JOB_NAME"
        aws sagemaker create-processing-job --region $AWS_REGION --processing-job-name $JOB_NAME \
            --role-arn $SAGEMAKER_ROLE_ARN --app-specification "{
             \"ImageUri\": \"361509912577.dkr.ecr.eu-west-1.amazonaws.com/timesheet-dq-processing:latest\",
             \"ContainerEntrypoint\": [\"python3\", \"/opt/ml/processing/code/data_quality.py\" ] }" \
           --processing-resources "{ \"ClusterConfig\": { \"InstanceType\": \"ml.t3.medium\", \"InstanceCount\": 1,
               \"VolumeSizeInGB\": 30 }}" \
           --processing-inputs "[ {
                    \"InputName\": \"input-data\",
                     \"S3Input\": {
                         \"S3Uri\": \"s3://bpl-timesheet-raw-dev/input/\",
                         \"LocalPath\": \"/opt/ml/processing/input\",
                         \"S3InputMode\": \"File\",                         
                          \"S3DataType\": \"S3Prefix\"  } }  ]" \
             --processing-output-config "{
                  \"Outputs\": [{
                   \"OutputName\": \"dq-output\",
                   \"S3Output\": {
                   \"S3Uri\": \"s3://bpl-timesheet-results-dev/output/\",
                  \"LocalPath\": \"/opt/ml/processing/output\",
                   \"S3UploadMode\": \"EndOfJob\"
                }
               }
              ]
             }"
      
               
artifacts:
  files:
    - '**/*'
